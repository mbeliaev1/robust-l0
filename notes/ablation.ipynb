{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stty: 'standard input': Inappropriate ioctl for device\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "root = os.path.abspath('/home/mbeliaev/home/code/robust-l0/')\n",
    "sys.path.append(root)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import foolbox\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from randomizedAblation import foolbox_utils\n",
    "from randomizedAblation.prog_bar import progress_bar\n",
    "import randomizedAblation.utils_color as utils_cifar\n",
    "import randomizedAblation.utils as utils\n",
    "import randomizedAblation.pytorch_cifar.models.resnet as resnet\n",
    "\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-49.5  50.5]\n"
     ]
    }
   ],
   "source": [
    "in_b = np.array([0,1])\n",
    "beta = 100\n",
    "\n",
    "out = in_b/(1/beta)\n",
    "out += ((1-beta)/2)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state_dict(torch_path):\n",
    "    # original saved file with DataParallel\n",
    "    state_dict = torch.load(torch_path)\n",
    "    # create new OrderedDict that does not contain `module.`\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict['net'].items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    return new_state_dict\n",
    "    # model.load_state_dict(new_state_dict)\n",
    "\n",
    "def load_ablation_model(dataset, parallel=True, device='cuda'):\n",
    "    assert dataset in ['MNIST', 'CIFAR']\n",
    "    is_MNIST = (dataset=='MNIST')\n",
    "\n",
    "    device = 'cuda'\n",
    "    class Flatten(nn.Module):\n",
    "        def forward(self, x):\n",
    "            return x.view(x.size(0), -1)\n",
    "    transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    if is_MNIST: \n",
    "        model_path = 'mnist_lr_0.001_keep_45_epoch_399_resume_mnist_lr_0.01_keep_45_epoch_199.pth.pth'\n",
    "        net = nn.Sequential(\n",
    "                nn.Conv2d(2, 64, 4, stride=2, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "                nn.ReLU(),\n",
    "                Flatten(),\n",
    "                nn.Linear(128*7*7,500),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(500,100),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(100, 10)\n",
    "            )\n",
    "        net = net.to(device)\n",
    "        keep = 45\n",
    "        bs = 5\n",
    "        # NOTE: DEFAULT VALUE 10000\n",
    "        samples = 10000\n",
    "        is_MNIST = True\n",
    "        dataset = torchvision.datasets.MNIST(root=root+'/datasets/', train=False, download=True, transform=transform_test)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=False, num_workers=1)\n",
    "\n",
    "    else:\n",
    "        model_path = 'cifar_lr_0.001_regularization_0.0005_model_resnet18_keep_75_epoch_399_resume_cifar_lr_0.01_regularization_0.0005_model_resnet18_keep_75_epoch_199.pth.pth'\n",
    "        net = resnet.ResNet18()\n",
    "        net = net.to(device)\n",
    "        keep = 75\n",
    "        bs = 2\n",
    "        # NOTE: DEFAULT VALUE 10000\n",
    "        samples = 2000\n",
    "        is_MNIST = False\n",
    "        dataset = torchvision.datasets.CIFAR10(root=root+'/datasets/CIFAR/', train=False, download=True, transform=transform_test)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=False, num_workers=1)\n",
    "    checkpoint_dir = root+'/randomizedAblation/'+'checkpoints'\n",
    "    resume_file = '{}/{}'.format(checkpoint_dir, model_path)\n",
    "\n",
    "    if parallel:\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        checkpoint = torch.load(resume_file)\n",
    "        net.load_state_dict(checkpoint['net'])\n",
    "    else:\n",
    "        converted_dict = convert_state_dict(resume_file)\n",
    "        net.load_state_dict(converted_dict)    \n",
    "\n",
    "    net.eval()\n",
    "    cudnn.benchmark = True\n",
    "    alpha = 0.05\n",
    "    return net, loader, dataset, keep, alpha, bs, samples, is_MNIST\n",
    "\n",
    "def predict(inputs, net, keep, samples, alpha, is_MNIST):\n",
    "    if is_MNIST:\n",
    "        predicted = utils.predict(inputs, net, keep, samples, alpha)\n",
    "    else:\n",
    "        predicted = utils_cifar.predict(inputs, net, keep, samples, alpha)\n",
    "    \n",
    "    return predicted\n",
    "\n",
    "def evaluate(net, total, loader, keep, alpha, bs, samples, is_MNIST):\n",
    "    \n",
    "    num_batches = total//bs # samples to evaluate (assuming batch size is 1)\n",
    "    device = 'cuda'\n",
    "\n",
    "    # iniatilize \n",
    "    tot = 0\n",
    "    correct = 0\n",
    "    abstain = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "        if batch_idx >= num_batches:\n",
    "            break\n",
    "\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            predicted = predict(inputs, net, keep, samples, alpha, is_MNIST)\n",
    "            correct += (predicted == targets.cpu()).sum()\n",
    "            abstain += (predicted == -1).sum()\n",
    "            tot += predicted.shape[0]\n",
    "            progress_bar(batch_idx, len(loader), 'Acc: %.3f%% (%d/%d)' % (100.*correct/tot, correct, tot))\n",
    "    out = {\n",
    "        'total': tot,\n",
    "        'correct': correct,\n",
    "        'abstain': abstain\n",
    "    }\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.attack import attack\n",
    "\n",
    "net, loader, dataset, keep, alpha, _ , _, is_MNIST = load_ablation_model('MNIST')\n",
    "\n",
    "bs = 5\n",
    "data_x, data_y = [], []\n",
    "data_iter = iter(loader)\n",
    "\n",
    "for batch in range(20):\n",
    "    x, y = data_iter.next()\n",
    "    data_x.append(x)\n",
    "    data_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sparse-rs attack: 0/20 batches done\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbeliaev/miniconda3/envs/robust/lib/python3.8/site-packages/scipy/stats/_discrete_distns.py:78: RuntimeWarning: divide by zero encountered in _binom_pdf\n",
      "  return _boost._binom_pdf(x, n, p)\n",
      "/home/mbeliaev/home/code/robust-l0/utils/attacks/sparse_rs.py:952: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  ind_to_fool = acc.nonzero().squeeze()\n"
     ]
    }
   ],
   "source": [
    "budget = 12\n",
    "beta = 1\n",
    "\n",
    "r_acc, _, _, _ = attack(net, \n",
    "                        budget=budget, \n",
    "                        x=data_x,\n",
    "                        y=data_y,\n",
    "                        beta = beta,\n",
    "                        n_queries=10000,\n",
    "                        n_restarts=5,\n",
    "                        device='cuda:0',\n",
    "                        log_path='ablation_rs.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_pw_attack_ablation(fmodel, attack , dataset, num_iters, num_batches, device):\n",
    "#     '''\n",
    "#     Runs pointwise attack on model using x,y for ablation model\n",
    "#     NOTE: assumes x,y is list of tensors \n",
    "#     '''\n",
    "#     # run attack\n",
    "#     advs = []\n",
    "#     advs_dist = []\n",
    "#     # for batch in trange(num_batches):\n",
    "#     for batch in trange(num_batches):\n",
    "#         (x, y) = dataset[batch]\n",
    "#         x, y = x.unsqueeze(0).numpy(), np.array([y])\n",
    "#         # x and y are individual samples here\n",
    "#         adversarial_dists = []\n",
    "#         adversarials = []\n",
    "#         for _ in range(num_iters):\n",
    "#             adv_x = attack(x, y, unpack=False)\n",
    "#             distance = adv_x[0].distance.value\n",
    "#             original_class = adv_x[0].original_class\n",
    "#             output = adv_x[0].output\n",
    "#             # distance = [x.distance.value for x in adv_x]\n",
    "#             # original_class = [x.original_class for x in adv_x]\n",
    "#             # output = [x.output for x in adv_x]\n",
    "#             adversarial_dists.append(distance)\n",
    "#             adversarials.append({'distance': distance,'label': original_class, 'scores':  output})\n",
    "\n",
    "#         # find min\n",
    "#         mindex = np.argmin(adversarial_dists)\n",
    "#         advs.append(adversarials[mindex])\n",
    "#         advs_dist.append(adversarial_dists[mindex])\n",
    "\n",
    "#     advs_dist = np.asarray(advs_dist)\n",
    "#     print('Final median l0 distance: ',np.median(advs_dist))\n",
    "\n",
    "#     return advs, advs_dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net, loader, dataset, keep, alpha, bs, samples, is_MNIST = load_ablation_model('CIFAR')\n",
    "# # override samples\n",
    "# samples = 10000\n",
    "# # check clean accuracy using 20 samples|\n",
    "# # out = evaluate(net, 20, loader, keep, alpha, bs, samples, is_MNIST) \n",
    "# # print(out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_samples = 5\n",
    "# num_iters = 10\n",
    "\n",
    "# fmodel = foolbox_utils.AblatedTorchModel(model=net,\n",
    "#                                          num_samples=samples,\n",
    "#                                          keep=keep,\n",
    "#                                          bounds=(0, 1),\n",
    "#                                          num_classes=10,\n",
    "#                                          is_MNIST=is_MNIST)\n",
    "# haattack = foolbox.attacks.PointwiseAttack(model=fmodel, \n",
    "#                                            criterion=foolbox_utils.MisclassificationOrAbstain(samples, alpha), \n",
    "#                                            distance=foolbox.distances.L0)\n",
    "\n",
    "# advs, advs_dist = run_pw_attack_ablation(fmodel=fmodel,\n",
    "#                                          attack=haattack,\n",
    "#                                          dataset=dataset,\n",
    "#                                          num_iters=num_iters,\n",
    "#                                          num_batches=total_samples,\n",
    "#                                          device='cuda')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('robust')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acfbcb7204aabebe0fded38f32a9455336bc712d2a72fb977b5ecc1782ddc648"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
