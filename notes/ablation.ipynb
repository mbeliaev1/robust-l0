{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stty: 'standard input': Inappropriate ioctl for device\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "root = os.path.abspath('/home/mbeliaev/home/code/robust-l0/')\n",
    "sys.path.append(root)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import foolbox\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from randomizedAblation import foolbox_utils\n",
    "from randomizedAblation.prog_bar import progress_bar\n",
    "import randomizedAblation.utils_color as utils_cifar\n",
    "import randomizedAblation.utils as utils\n",
    "import randomizedAblation.pytorch_cifar.models.resnet as resnet\n",
    "\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-49.5  50.5]\n"
     ]
    }
   ],
   "source": [
    "in_b = np.array([0,1])\n",
    "beta = 100\n",
    "\n",
    "out = in_b/(1/beta)\n",
    "out += ((1-beta)/2)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state_dict(torch_path):\n",
    "    # original saved file with DataParallel\n",
    "    state_dict = torch.load(torch_path)\n",
    "    # create new OrderedDict that does not contain `module.`\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict['net'].items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    return new_state_dict\n",
    "    # model.load_state_dict(new_state_dict)\n",
    "\n",
    "def load_ablation_model(dataset, parallel=True, device='cuda'):\n",
    "    assert dataset in ['MNIST', 'CIFAR']\n",
    "    is_MNIST = (dataset=='MNIST')\n",
    "\n",
    "    device = 'cuda'\n",
    "    class Flatten(nn.Module):\n",
    "        def forward(self, x):\n",
    "            return x.view(x.size(0), -1)\n",
    "    transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    if is_MNIST: \n",
    "        model_path = 'mnist_lr_0.001_keep_45_epoch_399_resume_mnist_lr_0.01_keep_45_epoch_199.pth.pth'\n",
    "        net = nn.Sequential(\n",
    "                nn.Conv2d(2, 64, 4, stride=2, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "                nn.ReLU(),\n",
    "                Flatten(),\n",
    "                nn.Linear(128*7*7,500),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(500,100),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(100, 10)\n",
    "            )\n",
    "        net = net.to(device)\n",
    "        keep = 45\n",
    "        bs = 5\n",
    "        # NOTE: DEFAULT VALUE 10000\n",
    "        samples = 10000\n",
    "        is_MNIST = True\n",
    "        dataset = torchvision.datasets.MNIST(root=root+'/datasets/', train=False, download=True, transform=transform_test)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=False, num_workers=1)\n",
    "\n",
    "    else:\n",
    "        model_path = 'cifar_lr_0.001_regularization_0.0005_model_resnet18_keep_75_epoch_399_resume_cifar_lr_0.01_regularization_0.0005_model_resnet18_keep_75_epoch_199.pth.pth'\n",
    "        net = resnet.ResNet18()\n",
    "        net = net.to(device)\n",
    "        keep = 75\n",
    "        bs = 2\n",
    "        # NOTE: DEFAULT VALUE 10000\n",
    "        samples = 2000\n",
    "        is_MNIST = False\n",
    "        dataset = torchvision.datasets.CIFAR10(root=root+'/datasets/CIFAR/', train=False, download=True, transform=transform_test)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=False, num_workers=1)\n",
    "    checkpoint_dir = root+'/randomizedAblation/'+'checkpoints'\n",
    "    resume_file = '{}/{}'.format(checkpoint_dir, model_path)\n",
    "\n",
    "    if parallel:\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        checkpoint = torch.load(resume_file)\n",
    "        net.load_state_dict(checkpoint['net'])\n",
    "    else:\n",
    "        converted_dict = convert_state_dict(resume_file)\n",
    "        net.load_state_dict(converted_dict)    \n",
    "\n",
    "    net.eval()\n",
    "    cudnn.benchmark = True\n",
    "    alpha = 0.05\n",
    "    return net, loader, dataset, keep, alpha, bs, samples, is_MNIST\n",
    "\n",
    "def predict(inputs, net, keep, samples, alpha, is_MNIST):\n",
    "    if is_MNIST:\n",
    "        predicted = utils.predict(inputs, net, keep, samples, alpha)\n",
    "    else:\n",
    "        predicted = utils_cifar.predict(inputs, net, keep, samples, alpha)\n",
    "    \n",
    "    return predicted\n",
    "\n",
    "def evaluate(net, total, loader, keep, alpha, bs, samples, is_MNIST):\n",
    "    \n",
    "    num_batches = total//bs # samples to evaluate (assuming batch size is 1)\n",
    "    device = 'cuda'\n",
    "\n",
    "    # iniatilize \n",
    "    tot = 0\n",
    "    correct = 0\n",
    "    abstain = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "        if batch_idx >= num_batches:\n",
    "            break\n",
    "\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            predicted = predict(inputs, net, keep, samples, alpha, is_MNIST)\n",
    "            correct += (predicted == targets.cpu()).sum()\n",
    "            abstain += (predicted == -1).sum()\n",
    "            tot += predicted.shape[0]\n",
    "            progress_bar(batch_idx, len(loader), 'Acc: %.3f%% (%d/%d)' % (100.*correct/tot, correct, tot))\n",
    "    out = {\n",
    "        'total': tot,\n",
    "        'correct': correct,\n",
    "        'abstain': abstain\n",
    "    }\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from utils.attack import attack\n",
    "\n",
    "net, loader, dataset, keep, alpha, _ , _, is_MNIST = load_ablation_model('CIFAR')\n",
    "\n",
    "bs = 1\n",
    "data_x, data_y = [], []\n",
    "data_iter = iter(loader)\n",
    "\n",
    "for batch in range(2):\n",
    "    x, y = data_iter.next()\n",
    "    data_x.append(x)\n",
    "    data_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 single channel mode\n",
      "Running sparse-rs attack: 0/2 batches done\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbeliaev/home/code/robust-l0/utils/attacks/sparse_rs.py:952: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  ind_to_fool = acc.nonzero().squeeze()\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/mbeliaev/miniconda3/envs/robust/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/mbeliaev/miniconda3/envs/robust/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/mbeliaev/home/code/robust-l0/randomizedAblation/pytorch_cifar/models/resnet.py\", line 94, in forward\n    out = F.avg_pool2d(out, 4)\nRuntimeError: non-empty 3D or 4D input tensor expected but got ndim: 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/mbeliaev/home/code/robust-l0/notes/ablation.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22646863703138352d36342e6563652e756373622e656475222c2275736572223a226d62656c69616576227d/home/mbeliaev/home/code/robust-l0/notes/ablation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m budget \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22646863703138352d36342e6563652e756373622e656475222c2275736572223a226d62656c69616576227d/home/mbeliaev/home/code/robust-l0/notes/ablation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m beta \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22646863703138352d36342e6563652e756373622e656475222c2275736572223a226d62656c69616576227d/home/mbeliaev/home/code/robust-l0/notes/ablation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m r_acc, _, _, _ \u001b[39m=\u001b[39m attack(net, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22646863703138352d36342e6563652e756373622e656475222c2275736572223a226d62656c69616576227d/home/mbeliaev/home/code/robust-l0/notes/ablation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                         budget\u001b[39m=\u001b[39;49mbudget, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22646863703138352d36342e6563652e756373622e656475222c2275736572223a226d62656c69616576227d/home/mbeliaev/home/code/robust-l0/notes/ablation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m                         x\u001b[39m=\u001b[39;49mdata_x,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22646863703138352d36342e6563652e756373622e656475222c2275736572223a226d62656c69616576227d/home/mbeliaev/home/code/robust-l0/notes/ablation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m                         y\u001b[39m=\u001b[39;49mdata_y,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22646863703138352d36342e6563652e756373622e656475222c2275736572223a226d62656c69616576227d/home/mbeliaev/home/code/robust-l0/notes/ablation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m                         beta \u001b[39m=\u001b[39;49m beta,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22646863703138352d36342e6563652e756373622e656475222c2275736572223a226d62656c69616576227d/home/mbeliaev/home/code/robust-l0/notes/ablation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m                         n_queries\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22646863703138352d36342e6563652e756373622e656475222c2275736572223a226d62656c69616576227d/home/mbeliaev/home/code/robust-l0/notes/ablation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m                         n_restarts\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22646863703138352d36342e6563652e756373622e656475222c2275736572223a226d62656c69616576227d/home/mbeliaev/home/code/robust-l0/notes/ablation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m                         device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22646863703138352d36342e6563652e756373622e656475222c2275736572223a226d62656c69616576227d/home/mbeliaev/home/code/robust-l0/notes/ablation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m                         log_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtemp.log\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/home/code/robust-l0/utils/attack.py:168\u001b[0m, in \u001b[0;36mattack\u001b[0;34m(net, budget, x, y, beta, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m x_batch_beta \u001b[39m=\u001b[39m beta_transform(x_batch,beta)\n\u001b[1;32m    167\u001b[0m \u001b[39m# run batch and store in list\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m r_acc, b_x_adv, b_y_adv, b_i_adv \u001b[39m=\u001b[39m attack_batch(net, \n\u001b[1;32m    169\u001b[0m                                                 x_batch_beta\u001b[39m.\u001b[39;49mto(device), \n\u001b[1;32m    170\u001b[0m                                                 y_batch\u001b[39m.\u001b[39;49mto(device), \n\u001b[1;32m    171\u001b[0m                                                 adversary)\n\u001b[1;32m    172\u001b[0m b_x_adv \u001b[39m=\u001b[39m beta_revert(b_x_adv, beta)\n\u001b[1;32m    173\u001b[0m \u001b[39m# some batches might have different weight\u001b[39;00m\n",
      "File \u001b[0;32m~/home/code/robust-l0/utils/attack.py:77\u001b[0m, in \u001b[0;36mattack_batch\u001b[0;34m(net, x, y, adversary)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39m# attack images that need to be fooled\u001b[39;00m\n\u001b[1;32m     76\u001b[0m ind_to_fool \u001b[39m=\u001b[39m (pred \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mnonzero(as_tuple\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m---> 77\u001b[0m _, adv \u001b[39m=\u001b[39m adversary\u001b[39m.\u001b[39;49mperturb(x[ind_to_fool], y[ind_to_fool])\n\u001b[1;32m     79\u001b[0m n_missed \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(x) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(ind_to_fool) \u001b[39m# number of misclassified\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39m# classify perturbed images and compute robust accuracy\u001b[39;00m\n",
      "File \u001b[0;32m~/home/code/robust-l0/utils/attacks/sparse_rs.py:959\u001b[0m, in \u001b[0;36mRSAttack.perturb\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    956\u001b[0m x_to_fool \u001b[39m=\u001b[39m x[ind_to_fool]\u001b[39m.\u001b[39mclone()\n\u001b[1;32m    957\u001b[0m y_to_fool \u001b[39m=\u001b[39m y[ind_to_fool]\u001b[39m.\u001b[39mclone()\n\u001b[0;32m--> 959\u001b[0m qr_curr, adv_curr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattack_single_run(x_to_fool, y_to_fool)\n\u001b[1;32m    961\u001b[0m output_curr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(adv_curr)\n\u001b[1;32m    962\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargeted:\n",
      "File \u001b[0;32m~/home/code/robust-l0/utils/attacks/sparse_rs.py:351\u001b[0m, in \u001b[0;36mRSAttack.attack_single_run\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    348\u001b[0m         x_new[img, :, np_set \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m w, np_set \u001b[39m%\u001b[39m w] \u001b[39m=\u001b[39m new_clr\u001b[39m.\u001b[39mclone()\n\u001b[1;32m    350\u001b[0m \u001b[39m# compute loss of the new candidates\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m margin, loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmargin_and_loss(x_new, y_curr)\n\u001b[1;32m    352\u001b[0m n_queries[idx_to_fool] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    354\u001b[0m \u001b[39m# update best solution\u001b[39;00m\n",
      "File \u001b[0;32m~/home/code/robust-l0/utils/attacks/sparse_rs.py:124\u001b[0m, in \u001b[0;36mRSAttack.margin_and_loss\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmargin_and_loss\u001b[39m(\u001b[39mself\u001b[39m, x, y):\n\u001b[1;32m    120\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[39m    :param y:        correct labels if untargeted else target labels\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x)\n\u001b[1;32m    125\u001b[0m     xent \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(logits, y, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    126\u001b[0m     u \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/home/code/robust-l0/utils/attack.py:61\u001b[0m, in \u001b[0;36mBetaModel.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     60\u001b[0m     x_og \u001b[39m=\u001b[39m beta_revert(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta)\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x_og)\n",
      "File \u001b[0;32m~/home/code/robust-l0/utils/attack.py:25\u001b[0m, in \u001b[0;36mSingleChannelModel.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     23\u001b[0m     \u001b[39m# print('in single',x.view(x.shape[0], 3, x.shape[2], x.shape[3] // 3).shape)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[39m# print('call',x.shape)\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x\u001b[39m.\u001b[39;49mview(x\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], \u001b[39m3\u001b[39;49m, x\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m], x\u001b[39m.\u001b[39;49mshape[\u001b[39m3\u001b[39;49m] \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m3\u001b[39;49m))\n",
      "File \u001b[0;32m~/home/code/robust-l0/utils/attack.py:41\u001b[0m, in \u001b[0;36mAblation_wrapper.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     36\u001b[0m     \u001b[39m# values below are for MNIST\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[39m# predicted = utils.predict(x.to('cuda:0'), self.model, 45, 10000, 0.05)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m     \u001b[39m# values below are for CIFAR \u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[39m# default value is 10000 samples, but we set to 5000 due to memeory capacity\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     predicted \u001b[39m=\u001b[39m utils_cifar\u001b[39m.\u001b[39;49mpredict(x\u001b[39m.\u001b[39;49mto(\u001b[39m'\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m'\u001b[39;49m), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39m75\u001b[39;49m, \u001b[39m2000\u001b[39;49m, \u001b[39m0.05\u001b[39;49m)\n\u001b[1;32m     42\u001b[0m     predicted[predicted\u001b[39m<\u001b[39m\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m,\u001b[39m10\u001b[39m,(predicted\u001b[39m<\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m     43\u001b[0m     logits \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mone_hot(predicted, \u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/home/code/robust-l0/randomizedAblation/utils_color.py:73\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(batch, net, keep, num_samples, alpha, sub_batch)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(batch, net ,keep, num_samples, alpha, sub_batch \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m ):\n\u001b[0;32m---> 73\u001b[0m \tscores \u001b[39m=\u001b[39m avg_hard_forward(batch, net, num_samples, keep,sub_batch\u001b[39m=\u001b[39;49msub_batch)\n\u001b[1;32m     74\u001b[0m \ttoptwo \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtopk(scores\u001b[39m.\u001b[39mcpu(),\u001b[39m2\u001b[39m,\u001b[39msorted\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     75\u001b[0m \ttoptwoidx \u001b[39m=\u001b[39m toptwo[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/home/code/robust-l0/randomizedAblation/utils_color.py:37\u001b[0m, in \u001b[0;36mavg_hard_forward\u001b[0;34m(batch, net, num_samples, keep, sub_batch)\u001b[0m\n\u001b[1;32m     35\u001b[0m expanded \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mrepeat_interleave(num_samples,\u001b[39m0\u001b[39m) \u001b[39m# shape: batch*num_samples, etc\u001b[39;00m\n\u001b[1;32m     36\u001b[0m masked \u001b[39m=\u001b[39m random_mask_batch_one_sample(expanded, keep)\n\u001b[0;32m---> 37\u001b[0m soft \u001b[39m=\u001b[39m net(masked)\n\u001b[1;32m     38\u001b[0m votes \u001b[39m=\u001b[39m soft\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m     39\u001b[0m hard \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(soft\u001b[39m.\u001b[39mshape)\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:161\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule(\u001b[39m*\u001b[39minputs[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs[\u001b[39m0\u001b[39m])\n\u001b[1;32m    160\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[:\u001b[39mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 161\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_apply(replicas, inputs, kwargs)\n\u001b[1;32m    162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather(outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:171\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparallel_apply\u001b[39m(\u001b[39mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 171\u001b[0m     \u001b[39mreturn\u001b[39;00m parallel_apply(replicas, inputs, kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_ids[:\u001b[39mlen\u001b[39;49m(replicas)])\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:86\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m     output \u001b[39m=\u001b[39m results[i]\n\u001b[1;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m---> 86\u001b[0m         output\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m     87\u001b[0m     outputs\u001b[39m.\u001b[39mappend(output)\n\u001b[1;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/torch/_utils.py:428\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexc_type, \u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    425\u001b[0m     \u001b[39m# Some exceptions have first argument as non-str but explicitly\u001b[39;00m\n\u001b[1;32m    426\u001b[0m     \u001b[39m# have message field\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexc_type(message\u001b[39m=\u001b[39mmsg)\n\u001b[0;32m--> 428\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexc_type(msg)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/mbeliaev/miniconda3/envs/robust/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/mbeliaev/miniconda3/envs/robust/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/mbeliaev/home/code/robust-l0/randomizedAblation/pytorch_cifar/models/resnet.py\", line 94, in forward\n    out = F.avg_pool2d(out, 4)\nRuntimeError: non-empty 3D or 4D input tensor expected but got ndim: 4\n"
     ]
    }
   ],
   "source": [
    "budget = 20\n",
    "beta = 100\n",
    "\n",
    "r_acc, _, _, _ = attack(net, \n",
    "                        budget=budget, \n",
    "                        x=data_x,\n",
    "                        y=data_y,\n",
    "                        beta = beta,\n",
    "                        n_queries=500,\n",
    "                        n_restarts=1,\n",
    "                        device='cuda:0',\n",
    "                        log_path='temp.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_pw_attack_ablation(fmodel, attack , dataset, num_iters, num_batches, device):\n",
    "#     '''\n",
    "#     Runs pointwise attack on model using x,y for ablation model\n",
    "#     NOTE: assumes x,y is list of tensors \n",
    "#     '''\n",
    "#     # run attack\n",
    "#     advs = []\n",
    "#     advs_dist = []\n",
    "#     # for batch in trange(num_batches):\n",
    "#     for batch in trange(num_batches):\n",
    "#         (x, y) = dataset[batch]\n",
    "#         x, y = x.unsqueeze(0).numpy(), np.array([y])\n",
    "#         # x and y are individual samples here\n",
    "#         adversarial_dists = []\n",
    "#         adversarials = []\n",
    "#         for _ in range(num_iters):\n",
    "#             adv_x = attack(x, y, unpack=False)\n",
    "#             distance = adv_x[0].distance.value\n",
    "#             original_class = adv_x[0].original_class\n",
    "#             output = adv_x[0].output\n",
    "#             # distance = [x.distance.value for x in adv_x]\n",
    "#             # original_class = [x.original_class for x in adv_x]\n",
    "#             # output = [x.output for x in adv_x]\n",
    "#             adversarial_dists.append(distance)\n",
    "#             adversarials.append({'distance': distance,'label': original_class, 'scores':  output})\n",
    "\n",
    "#         # find min\n",
    "#         mindex = np.argmin(adversarial_dists)\n",
    "#         advs.append(adversarials[mindex])\n",
    "#         advs_dist.append(adversarial_dists[mindex])\n",
    "\n",
    "#     advs_dist = np.asarray(advs_dist)\n",
    "#     print('Final median l0 distance: ',np.median(advs_dist))\n",
    "\n",
    "#     return advs, advs_dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net, loader, dataset, keep, alpha, bs, samples, is_MNIST = load_ablation_model('CIFAR')\n",
    "# # override samples\n",
    "# samples = 10000\n",
    "# # check clean accuracy using 20 samples|\n",
    "# # out = evaluate(net, 20, loader, keep, alpha, bs, samples, is_MNIST) \n",
    "# # print(out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_samples = 5\n",
    "# num_iters = 10\n",
    "\n",
    "# fmodel = foolbox_utils.AblatedTorchModel(model=net,\n",
    "#                                          num_samples=samples,\n",
    "#                                          keep=keep,\n",
    "#                                          bounds=(0, 1),\n",
    "#                                          num_classes=10,\n",
    "#                                          is_MNIST=is_MNIST)\n",
    "# haattack = foolbox.attacks.PointwiseAttack(model=fmodel, \n",
    "#                                            criterion=foolbox_utils.MisclassificationOrAbstain(samples, alpha), \n",
    "#                                            distance=foolbox.distances.L0)\n",
    "\n",
    "# advs, advs_dist = run_pw_attack_ablation(fmodel=fmodel,\n",
    "#                                          attack=haattack,\n",
    "#                                          dataset=dataset,\n",
    "#                                          num_iters=num_iters,\n",
    "#                                          num_batches=total_samples,\n",
    "#                                          device='cuda')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('robust')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acfbcb7204aabebe0fded38f32a9455336bc712d2a72fb977b5ecc1782ddc648"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
